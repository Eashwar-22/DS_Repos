{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63fd4d2",
   "metadata": {},
   "source": [
    "# Flight Fare  Prediction\n",
    "\n",
    "**Objective :**<br>\n",
    "Predicting flight ticket prices based on the ticket details. This is a regression analysis since we are dealing with predicting the continuous variable (Price).<br>\n",
    "\n",
    "[**Click here to download the data**](https://www.kaggle.com/nikhilmittal/flight-fare-prediction-mh)\n",
    "\n",
    "\n",
    "\n",
    "**Data Pre-processing Steps involved**\n",
    "1. Dealing with missing data\n",
    "2. Dealing with datetime features\n",
    "3. Dealing with categorical features\n",
    "4. Dealing with imputation\n",
    "5. Feature Selection\n",
    "6. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b25004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pickle\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for table display\n",
    "sns.set_theme(style='whitegrid')\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from IPython.core import display as ICD\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7deab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending all functions in this block\n",
    "\n",
    "def convert_to_date(df,col):\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "\n",
    "def convert_and_drop(df,col,suffix):\n",
    "    \"\"\"\n",
    "    Transform datetime features\n",
    "    \"\"\"\n",
    "    if suffix=='_hour':\n",
    "        df[col+suffix] = df[col].dt.hour\n",
    "    elif suffix=='_minute':\n",
    "        df[col+suffix] = df[col].dt.minute\n",
    "    elif suffix=='_day':\n",
    "        df[col+suffix] = df[col].dt.day\n",
    "    elif suffix=='_month':\n",
    "        df[col+suffix] = df[col].dt.month\n",
    "\n",
    "def transform_duration(x):\n",
    "    \"\"\"\n",
    "    Transform the duration feature\n",
    "    \"\"\"\n",
    "    if len(x.split())==2:\n",
    "        return x\n",
    "    else:\n",
    "        if 'h' in x:\n",
    "            return x + ' 0m'\n",
    "        else:\n",
    "            return '0h '+ x\n",
    "\n",
    "def plot_dist(data,col):\n",
    "    \"\"\"\n",
    "    Plot distributions of a continuous variable\n",
    "    \"\"\"\n",
    "    fig,(ax1,ax2)=plt.subplots(2,1,figsize=(10,10))\n",
    "    ax1.set_title(f'Distribution of {col} with Skewness = {round(data[col].skew(),2)}',fontsize=16)\n",
    "    sns.distplot(data[col],ax=ax1);\n",
    "    sns.boxplot(data=data,x=col,ax=ax2);\n",
    "\n",
    "def prediction(model,dump_filename=None):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(\"Training Score : \",round(model.score(X_train,y_train),2))\n",
    "    print(\"Test Score : \",round(model.score(X_test,y_test),2))\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"R2 Score : \",round(r2_score(y_test,y_pred),2))\n",
    "    print(\"MAE : \",round(mean_absolute_error(y_test,y_pred),2))\n",
    "    print(\"MSE : \",round(mean_squared_error(y_test,y_pred),2))\n",
    "    print(\"RMSE : \",round(np.sqrt(mean_squared_error(y_test,y_pred)),2))\n",
    "    \n",
    "    variance = pd.DataFrame(np.array(y_test)-y_pred,columns=['y_test-y_pred'])\n",
    "    plot_dist(variance,'y_test-y_pred')\n",
    "    \n",
    "    if dump_filename is not None:\n",
    "        file = open(f'../Model/{dump_filename}.pkl')\n",
    "        pickle.dump(model,file)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945ce384",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Data_Train.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a6195dcd8829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/Data_Train.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[0;32m-> 1192\u001b[0;31m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m                 )\n\u001b[1;32m   1194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     with get_handle(\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     ) as handle:\n\u001b[1;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Data_Train.xlsx'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('../Data/Data_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b568088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eashwar/Documents/Learning/Flight_Fare_Prediction'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4498ba5",
   "metadata": {},
   "source": [
    "### 1. Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe80de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(data.isnull());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84087c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum(),data.shape,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values can be dropped\n",
    "df1 = data.dropna(axis='rows')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cb62d",
   "metadata": {},
   "source": [
    "### 2. Dealing with Datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b8161",
   "metadata": {},
   "source": [
    "`Date_of_Journey` ---> `datetime`   _(extract day and month)_ <br>\n",
    "`Dep_Time` ---> `datetime`   _(extract hour and minute)_ <br>\n",
    "`Arrival_Time` ---> `datetime`   _(extract hour and minute)_ <br>\n",
    "`Duration` ---> `numerical`  _(extract hour and minute)_<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e523cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.copy()\n",
    "\n",
    "# convert the features to datetime; extract the necessary metrics\n",
    "date_cols = ['Date_of_Journey','Dep_Time','Arrival_Time']\n",
    "for i in date_cols:\n",
    "    convert_to_date(df2,i)\n",
    "    if i=='Date_of_Journey':\n",
    "        convert_and_drop(df2,i,'_day')\n",
    "        convert_and_drop(df2,i,'_month')\n",
    "    else:\n",
    "        convert_and_drop(df2,i,'_hour')\n",
    "        convert_and_drop(df2,i,'_minute')\n",
    "\n",
    "# extract hours and minutes from Duration column; convert them to integers\n",
    "df2['Duration'] = df2['Duration'].apply(lambda x : transform_duration(x))\n",
    "df2['Duration_hour']  = df2['Duration'].apply(lambda x : int(x.split(' ')[0][0:-1]))\n",
    "df2['Duration_minute']  = df2['Duration'].apply(lambda x : int(x.split(' ')[1][0:-1]))\n",
    "\n",
    "\n",
    "# drop unnecessary columns\n",
    "df2.drop(columns=date_cols+['Duration'],inplace=True)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73987063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38358838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all numerical features in one dataframe\n",
    "\n",
    "num_cols = [col for col in df2.columns if df2[col].dtype!='O']\n",
    "print(\"Numerical columns : \",num_cols)\n",
    "numerical = df2[num_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3734fe",
   "metadata": {},
   "source": [
    "### 3. Dealing with Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d29ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categorical columns\n",
    "cat_cols = [col for col in df2.columns if df2[col].dtype=='O']\n",
    "df_cat = df2[cat_cols].copy()\n",
    "print(cat_cols)\n",
    "print(df2[cat_cols].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13511e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airline vs Price Distribution\n",
    "\n",
    "print(df2['Airline'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.title('Airline vs Price Distribution',fontsize=16)\n",
    "plt.ylabel('Price',fontsize=16)\n",
    "plt.xlabel('Airline',fontsize=16)\n",
    "\n",
    "sns.boxplot(data=df2.sort_values(by='Price',ascending=False),x='Airline',y='Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405b0cb",
   "metadata": {},
   "source": [
    "_Jet Airways charged tickets at a higher rate with negligible fluctuation.<br>\n",
    "Other Airlines charged tickets almost within the same range._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc01617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source vs Price Distribution\n",
    "\n",
    "print(df2['Source'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.title('Source vs Price Distribution',fontsize=16)\n",
    "plt.ylabel('Price',fontsize=16)\n",
    "plt.xlabel('Source',fontsize=16)\n",
    "\n",
    "sns.boxplot(data=df2.sort_values(by='Price',ascending=False),x='Source',y='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19775de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination vs Price Distribution\n",
    "\n",
    "print(df2['Destination'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.title('Destination vs Price Distribution',fontsize=16)\n",
    "plt.ylabel('Price',fontsize=16)\n",
    "plt.xlabel('Destination',fontsize=16)\n",
    "\n",
    "sns.boxplot(data=df2.sort_values(by='Price',ascending=False),x='Destination',y='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1732ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Stops vs Price Distribution\n",
    "\n",
    "print(df2['Total_Stops'].value_counts())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.title('Total Stops vs Price Distribution',fontsize=16)\n",
    "plt.ylabel('Price',fontsize=16)\n",
    "plt.xlabel('Total Stops',fontsize=16)\n",
    "\n",
    "sns.boxplot(data=df2.sort_values(by='Price',ascending=False),x='Total_Stops',y='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEALING WITH 'Route' COLUMN\n",
    "\n",
    "print(df2['Route'].head(5))\n",
    "print('\\n')\n",
    "print(\"Distinct number of routes : \",df2['Route'].apply(lambda x: len(x.split('→'))).unique())\n",
    "print(\"Maximum number of routes → 6-1=5\")\n",
    "\n",
    "# Split the routes into 5 (maximum routes) seperate columns\n",
    "df_cat['Route_1']=df_cat['Route'].str.split('→').str[0]\n",
    "df_cat['Route_2']=df_cat['Route'].str.split('→').str[1]\n",
    "df_cat['Route_3']=df_cat['Route'].str.split('→').str[2]\n",
    "df_cat['Route_4']=df_cat['Route'].str.split('→').str[3]\n",
    "df_cat['Route_5']=df_cat['Route'].str.split('→').str[4]\n",
    "\n",
    "# replace empty routes with 'None'\n",
    "for i in ['Route_3','Route_4','Route_5']:\n",
    "    df_cat[i].fillna('None',inplace=True)\n",
    "\n",
    "# drop original column\n",
    "df_cat.drop(columns='Route',inplace=True)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of distinct values in each categorical feature\")\n",
    "df_cat.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6603a1",
   "metadata": {},
   "source": [
    "**Encoding Approach**<br>\n",
    "- One-hot encoding needed for ['Airline','Source','Destination'].\n",
    "- 'Total_Stops' can be converted to number of stops. (non-stop→0, 1 stop→1, 2 stops→2, ...)\n",
    "- 'Additional_Info' can be dropped.\n",
    "- Label encoding needed for the 5 Routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70608f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "Airline = pd.get_dummies(df_cat['Airline'],drop_first=True)\n",
    "Source = pd.get_dummies(df_cat['Source'],drop_first=True)\n",
    "Destination = pd.get_dummies(df_cat['Destination'],drop_first=True)\n",
    "ICD.display('Airline',Airline.head())\n",
    "ICD.display('Source',Source.head())\n",
    "ICD.display('Destination',Destination.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de01ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "route_cols = ['Route_1', 'Route_2','Route_3', 'Route_4', 'Route_5']\n",
    "Routes=df_cat[route_cols].copy()\n",
    "\n",
    "for i in route_cols:\n",
    "    Routes[i]=label_enc.fit_transform(Routes[i])\n",
    "\n",
    "ICD.display('Routes',Routes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom encoding on 'Total_Stops'\n",
    "\n",
    "ICD.display(df_cat['Total_Stops'].head())\n",
    "print(\"Distinct Total_Stops : \",df_cat['Total_Stops'].unique())\n",
    "dict_stops = {'non-stop':0,'1 stop':1,'2 stops':2,'3 stops':3,'4 stops':4}\n",
    "Total_Stops = df_cat['Total_Stops'].map(dict_stops)\n",
    "ICD.display('Total_Stops',Total_Stops.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all transformed columns\n",
    "categorical = pd.concat([Airline,Source,Destination,Routes,Total_Stops],axis=1)\n",
    "df3 = pd.concat([categorical,numerical],axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be518835",
   "metadata": {},
   "source": [
    "### 4. Dealing with Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f64450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.copy()\n",
    "plot_dist(df4,'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e470039a",
   "metadata": {},
   "source": [
    "Prices > 40000 could be considered as outliers, to be replaced with median price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac12a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Price'] = np.where(df4['Price']>40000,df4['Price'].median(),df4['Price'])\n",
    "plot_dist(df4,'Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4.drop(columns='Price')\n",
    "y = df4['Price']\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91154202",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICD.display('Features',X.head())\n",
    "ICD.display('Target',y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd4642",
   "metadata": {},
   "source": [
    "### 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00190c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 correlated features with Price (by magnitude)\n",
    "corr_price = df4.corr()[['Price']]\n",
    "corr_price['abs_Price'] = corr_price.abs()\n",
    "corr_price = corr_price.sort_values(by='abs_Price',ascending=False)\n",
    "corr_price.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottom 5 correlated features with Price\n",
    "corr_price.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbe072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting features based on importance\n",
    "col_dep = pd.DataFrame(mutual_info_classif(X,y),index=X.columns,columns=['Importance'])\n",
    "col_dep.sort_values(inplace=True,by='Importance',ascending=False)\n",
    "col_dep.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dep.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e47e4",
   "metadata": {},
   "source": [
    "Based on the two observations, feature 'Jet Airways Business' can be dropped due to irrelevance with the target variable - Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a657437",
   "metadata": {},
   "source": [
    "### 6. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=27)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dca5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "prediction(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d076785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "prediction(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04581f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1023dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
